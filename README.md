Complex Graph Analytics Group Paper Reading List
===============================

Seminars
--------

### Spring 2024

|**Date**| **Paper Title**                                                           | **Presenter** | **Notes** | **Published** |
|--------|---------------------------------------------------------------------------|---------------|-----------|---------------|
| 07.19  | [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062) | JinChao Yan | [Slides](./Slides/bigbird.pptx) |NeurIPS2020|
| 06.28  | [Reformer: The Efficient Transformer](https://arxiv.org/abs/2001.04451) | JinChao Yan | [Slides](./Slides/reformer.pptx) |ICLR2020|
| 05.31  | [A3: Accelerating Attention Mechanisms in Neural Networks with Approximation](https://ieeexplore.ieee.org/document/9065498) | JinChao Yan  | [Slides](./Slides/a3_slide_hpca2020.pptx) |HPCA2020|
| 06.07  | [SpAtten: EfÔ¨Åcient Sparse Attention Architecture with Cascade Token and Head Pruning](https://ieeexplore.ieee.org/document/9407232) | JinChao Yan | [Slides](./Slides/SpAtten-for-long-video-no-animation.pdf) |HPCA2021|
| 06.12  | [Sanger: A Co-Design Framework for Enabling Sparse Attention using Reconfigurable Architecture](https://dl.acm.org/doi/10.1145/3466752.3480125) | JinChao Yan | [Slides](./Slides/Sanger.pptx) |MICRO2021|
| 07.26  | [DOTA: detect and omit weak attentions for scalable transformer acceleration](5https://dl.acm.org/doi/10.1145/3503222.3507738) | JinChao Yan | [Slides](./Slides/dota.pptx) |ASPLOS2022|
|   | [FACT: FFN-Attention Co-optimized Transformer Architecture with Eager Correlation Prediction](https://dl.acm.org/doi/10.1145/3579371.3589057) | JinChao Yan | [Slides](./Slides/FACT.pdf) |ISCA2023|

Reading List From Other Groups
------------------------------

-   [University of Sydney, Future System Architecture Lab](https://github.com/usyd-fsalab/ReadingList)
-   [SJTU-ReArch-Group](https://github.com/SJTU-ReArch-Group/Paper-Reading-List)

